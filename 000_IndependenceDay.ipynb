{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "000_IndependenceDay",
      "provenance": [],
      "collapsed_sections": [
        "lF-nLCGVJUma",
        "DM4FG_ddMU2R",
        "Nx4UbELeSO5O"
      ],
      "authorship_tag": "ABX9TyOApy/CbVQnqi+HID26ocQn"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "npyJbzO3VlUd",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# %%time\n",
        "\n",
        "# from google.colab import files\n",
        "\n",
        "# uploaded = files.upload()"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZIz7aTplVq9T",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 105
        },
        "outputId": "c014d943-a9f1-4850-97ea-481f80a6e203"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "\n",
        "import string\n",
        "import re\n",
        "import nltk\n",
        "from nltk.corpus import stopwords\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.feature_extraction.text import CountVectorizer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from collections import defaultdict, Counter\n",
        "\n",
        "from sklearn.naive_bayes import MultinomialNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.multiclass import OneVsRestClassifier\n",
        "from sklearn.metrics import accuracy_score, precision_score, recall_score\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings('ignore')\n",
        "\n",
        "nltk.download('stopwords')\n",
        "stop_words = set(stopwords.words('english'))"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/statsmodels/tools/_testing.py:19: FutureWarning: pandas.util.testing is deprecated. Use the functions in the public API at pandas.testing instead.\n",
            "  import pandas.util.testing as tm\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xeA5qaCMKo82",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# # import tensorflow as tf\n",
        "\n",
        "# !pip install -q tensorflow-hub\n",
        "# !pip install -q tensorflow-datasets\n",
        "# import tensorflow_hub as hub\n",
        "# import tensorflow_datasets as tfds\n",
        "\n",
        "# from keras.losses import categorical_crossentropy\n",
        "# from keras.optimizers import Adam\n",
        "# from keras.callbacks import EarlyStopping"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k6uyBxhPalOU",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train = pd.read_csv('train.csv')\n",
        "test = pd.read_csv('test.csv')"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lF-nLCGVJUma",
        "colab_type": "text"
      },
      "source": [
        "## Text Cleanup"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0g3iAf36bEMQ",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "def cleanup_df(df, column):\n",
        "  num_pattern = re.compile(r'[0-9]+')\n",
        "  single_word_pattern = re.compile(r'^[a-zA-Z]?$')\n",
        "  df[column] = df[column].apply(lambda x: x.replace('\\n',' ').\\\n",
        "                            replace('(','').replace(')','').\\\n",
        "                            replace('/', ' ').lower())\n",
        "  # df[column] = df[column].apply(lambda x: re.sub(r'[0-9]+','', x))\n",
        "  df[column] = df[column].apply(lambda x: x.split(' '))\n",
        "  df[column] = df[column].apply(lambda x: [w for w in x if not num_pattern.match(w)])\n",
        "  # df[column] = df[column].apply(lambda x: [w for w in x if not single_word_pattern.match(w)]) \n",
        "  df[column] = df[column].apply(lambda x: [c for c in x if c not in '' if c \n",
        "                                           not in stop_words])\n",
        "  df[column] = df[column].apply(lambda x: ' '.join(x))\n",
        "\n",
        "  return df"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0zgNNmR9bQnZ",
        "colab_type": "code",
        "cellView": "both",
        "colab": {}
      },
      "source": [
        "train = cleanup_df(train, 'ABSTRACT')\n",
        "test = cleanup_df(test, 'ABSTRACT')"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0jjVNEWLh99",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['all_text'] = train.TITLE.values + '. ' + train.ABSTRACT.values\n",
        "test['all_text'] = test.TITLE.values + '. ' + test.ABSTRACT.values\n",
        "\n",
        "train['all_text'] = train['all_text'].apply(lambda x: x.lower())\n",
        "test['all_text'] = test['all_text'].apply(lambda x: x.lower())"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuuXJIccgb3I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "61f644da-1f7f-4dde-f388-4e35c43135b7"
      },
      "source": [
        "train['all_text'][2]"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'spherical polyharmonics and poisson kernels for polyharmonic functions. introduce develop notion spherical polyharmonics, natural generalisation spherical harmonics. particular study theory zonal polyharmonics, allows us, analogously zonal harmonics, construct poisson kernels polyharmonic functions union rotated balls. find representation poisson kernels zonal polyharmonics terms gegenbauer polynomials. show connection classical poisson kernel harmonic functions ball, poisson kernels polyharmonic functions union rotated balls, cauchy-hua kernel holomorphic functions lie ball.'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ugUqQD8AfLAt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# all_words = []\n",
        "# for i in range(0, len(train)):\n",
        "#   tmp = train['all_text'][i].split(' ')\n",
        "#   for l in range(0, len(tmp)):\n",
        "#     all_words.append(tmp[l])\n",
        "\n",
        "# len(all_words)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "d9iboUpkhY6c",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# c = Counter(all_words)\n",
        "# c.most_common()[600:1000]"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DM4FG_ddMU2R",
        "colab_type": "text"
      },
      "source": [
        "## Naive Bayes Classifier"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kPWKlBVAaqKr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_cols = ['Computer Science', 'Physics', 'Mathematics', 'Statistics',\n",
        "               'Quantitative Biology', 'Quantitative Finance']\n",
        "\n",
        "def naivebayesclassifier(train, test, column_index):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(train['all_text'],\n",
        "                                                      train[target_cols[column_index]],\n",
        "                                                      random_state=1)\n",
        "  cv = CountVectorizer()\n",
        "\n",
        "  X_train_cv = cv.fit_transform(X_train)\n",
        "  X_test_cv = cv.transform(X_test)\n",
        "\n",
        "  nb = MultinomialNB()\n",
        "  nb.fit(X_train_cv, y_train)\n",
        "  predictions = nb.predict(X_test_cv)\n",
        "\n",
        "  print('Accuracy score: ', accuracy_score(y_test, predictions))\n",
        "  print('Precision score: ', precision_score(y_test, predictions))\n",
        "  print('Recall score: ', recall_score(y_test, predictions))\n",
        "\n",
        "  df_test = cv.transform(test['all_text'])\n",
        "  test_pred = nb.predict(df_test)\n",
        "\n",
        "  return pd.Series(test_pred)"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-IwUwFHJBLKX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "cd9ad760-3b07-4160-ad12-47db849ef7b5"
      },
      "source": [
        "nb_pred_0 = naivebayesclassifier(train, test, 0)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score:  0.8502765592218196\n",
            "Precision score:  0.7645891226677253\n",
            "Recall score:  0.9093484419263456\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k2CEMbgZdMjj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "a98c7afa-ed2e-4cc8-d7e6-525dfbfac791"
      },
      "source": [
        "nb_pred_1 = naivebayesclassifier(train, test, 1)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score:  0.9300019073049781\n",
            "Precision score:  0.9074204946996467\n",
            "Recall score:  0.8447368421052631\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SqkWB1oWdOkI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "ee4fabf3-e888-4119-fc9f-ec5e8f745181"
      },
      "source": [
        "nb_pred_2 = naivebayesclassifier(train, test, 2)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score:  0.8880411977875262\n",
            "Precision score:  0.7705345501955672\n",
            "Recall score:  0.8341566690190544\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gct1NBGCdOYX",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "1cee799b-ddef-4893-83dc-ca1d9eb8b366"
      },
      "source": [
        "nb_pred_3 = naivebayesclassifier(train, test, 3)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score:  0.8447453747854282\n",
            "Precision score:  0.6203353163872364\n",
            "Recall score:  0.9110405083399523\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MZSmG0xXdOKR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "e726fa61-8772-40b9-98e1-bb8b4e7f8d7d"
      },
      "source": [
        "nb_pred_4 = naivebayesclassifier(train, test, 4)"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score:  0.9746328437917223\n",
            "Precision score:  0.6329113924050633\n",
            "Recall score:  0.3246753246753247\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "472hQOKddN68",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "599d77f7-c10f-407f-e4dd-18e9566ab9dd"
      },
      "source": [
        "nb_pred_5 = naivebayesclassifier(train, test, 5)"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score:  0.9906542056074766\n",
            "Precision score:  0.9411764705882353\n",
            "Recall score:  0.25\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kN5W0olLVis2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_test_preds = pd.concat((test['ID'], nb_pred_0, nb_pred_1, nb_pred_2,\n",
        "                           nb_pred_3, nb_pred_4, nb_pred_5), axis=1)\n",
        "nb_test_preds.columns = ['ID'] + target_cols"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "07aWuts3WEQB",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "nb_test_preds.to_csv('nbcountvecclassifier_08222020.csv', index=False)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Nx4UbELeSO5O",
        "colab_type": "text"
      },
      "source": [
        "## Logistic Regression with OVR"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fjQVgmcWSR9h",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "target_cols = ['Computer Science', 'Physics', 'Mathematics', 'Statistics',\n",
        "               'Quantitative Biology', 'Quantitative Finance']\n",
        "\n",
        "def logisticclassifier(train, test, column_index):\n",
        "  X_train, X_test, y_train, y_test = train_test_split(train['all_text'],\n",
        "                                                      train[target_cols[column_index]],\n",
        "                                                      random_state=1)\n",
        "  cv = CountVectorizer()\n",
        "\n",
        "  X_train_cv = cv.fit_transform(X_train)\n",
        "  X_test_cv = cv.transform(X_test)\n",
        "\n",
        "  lr = LogisticRegression(multi_class='ovr')\n",
        "  lr.fit(X_train_cv, y_train)\n",
        "  predictions = lr.predict(X_test_cv)\n",
        "\n",
        "  print('Accuracy score: ', accuracy_score(y_test, predictions))\n",
        "  print('Precision score: ', precision_score(y_test, predictions))\n",
        "  print('Recall score: ', recall_score(y_test, predictions))\n",
        "\n",
        "  df_test = cv.transform(test['all_text'])\n",
        "  test_pred = lr.predict(df_test)\n",
        "\n",
        "  return pd.Series(test_pred)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PRY8kTkfYvyq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "a840c62b-a875-4142-9f3d-f388b688bb99"
      },
      "source": [
        "lr_pred_0 = logisticclassifier(train, test, 0)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score:  0.8369254243753577\n",
            "Precision score:  0.8017200191113235\n",
            "Recall score:  0.7922568460812087\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1J7T7ME5Y3tE",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "3a36e518-13c6-4677-a083-ebaa07b4b93f"
      },
      "source": [
        "lr_pred_1 = logisticclassifier(train, test, 1)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score:  0.9254243753576197\n",
            "Precision score:  0.8939288206559665\n",
            "Recall score:  0.8427631578947369\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kImtW19oZDFT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "8b57cdd1-967b-4eac-e295-d276c305200e"
      },
      "source": [
        "lr_pred_2 = logisticclassifier(train, test, 2)"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score:  0.8891855807743658\n",
            "Precision score:  0.8051094890510949\n",
            "Recall score:  0.7784050811573747\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QZ5377z8ZFaI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "cba57e9a-1a34-41fb-c35a-30f4b0eabb40"
      },
      "source": [
        "lr_pred_3 = logisticclassifier(train, test, 3)"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score:  0.8630555025748617\n",
            "Precision score:  0.7193836171938361\n",
            "Recall score:  0.704527402700556\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A3bcn8WrZGlw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "041ecda2-b6ed-4f13-9403-31efe7ed2858"
      },
      "source": [
        "lr_pred_4 = logisticclassifier(train, test, 4)"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score:  0.9721533473202365\n",
            "Precision score:  0.5487804878048781\n",
            "Recall score:  0.2922077922077922\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vakFJZhXZHze",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 0
        },
        "outputId": "597380e7-d88f-4c71-83c2-9a3892166792"
      },
      "source": [
        "lr_pred_5 = logisticclassifier(train, test, 5)"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy score:  0.9908449361052832\n",
            "Precision score:  0.6904761904761905\n",
            "Recall score:  0.453125\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "CV0UtGZ4ZTUa",
        "colab": {}
      },
      "source": [
        "lr_test_preds = pd.concat((test['ID'], lr_pred_0, lr_pred_1, lr_pred_2,\n",
        "                           lr_pred_3, lr_pred_4, lr_pred_5), axis=1)\n",
        "lr_test_preds.columns = ['ID'] + target_cols"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab_type": "code",
        "id": "6dZP1UVgZTUh",
        "colab": {}
      },
      "source": [
        "lr_test_preds.to_csv('lrcountvecclassifier_08222020.csv', index=False)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ogcqwq_2asjJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "combo_test_preds = pd.concat((test['ID'], nb_pred_0, nb_pred_1, nb_pred_2,\n",
        "                              nb_pred_3, nb_pred_4, lr_pred_5), axis=1)\n",
        "combo_test_preds.columns = ['ID'] + target_cols\n",
        "\n",
        "combo_test_preds.to_csv('combocountvecclassifier_08222020.csv', index=False)"
      ],
      "execution_count": 30,
      "outputs": []
    }
  ]
}